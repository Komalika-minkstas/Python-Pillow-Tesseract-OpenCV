import kraken
from kraken import pageseg
from PIL import Image

help(kraken)
help(pageseg)

im=Image.open('readonly/two_col.png')
display(im)
bounding_boxes=pageseg.segment(im.convert('1'))['boxes']
print(bounding_boxes)

def show_boxes(img):
    '''Modifies the passed image to show a series of bounding boxes on an image as run by kraken
    :param img: A PIL.Image object
    :return img:The modifies PIL.Image object
    '''
    from PIL import ImageDraw
    drawing_object=ImageDraw.Draw(img)
    bounding_boxes=pageseg.segment(img.convert('1'))['boxes']
    
    for box in bounding_boxes:
        drawing_object.rectangle(box, fill=None, outline='red')
    return img
display(show_boxes(Image.open('readonly/two_col.png')))

def show_boxes(img):
    '''Modifies the passed image to show a series of bounding boxes on an image as run by kraken
    :param img: A PIL.Image object
    :return img:The modifies PIL.Image object
    '''
    from PIL import ImageDraw
    drawing_object=ImageDraw.Draw(img)
    bounding_boxes=pageseg.segment(img.convert('1'),black_colseps=True)['boxes']
    
    for box in bounding_boxes:
        drawing_object.rectangle(box, fill=None, outline='red')
    return img
display(show_boxes(Image.open('readonly/two_col.png')))

char_width=25
def calculate_line_height(img):
    '''calculate the average height of a line from a given image
    :param img:A PIL.Image object
    :return:The average height of line in pixels
    '''
    bounding_boxes=pageseg.segment(img.convert('1'))['boxes']
    height_accumulator=0
    for box in bounding_boxes:
        height_accumulator=height_accumulator+box[3]-box[1]
    return int((height_accumulator)/len(bounding_boxes))
line_height=calculate_line_height(Image.open('readonly/two_col.png'))
print(line_height)

gap_box=(0,0,char_width,line_height*6)
gap_box

def gap_check(img, location):
    '''check a given image at a location(x,y) if it fits the description of a given box
    :param img: A PIL.Image file
    :param location:a tuple(x,y) which is a pixel location of that image
    :return:True if it fits the definition of a gap_box else false
    '''
    for x in range(location[0],location[0]+gap_box[2]):
        for y in range(location[1], location[1]+gap_box[3]):
            if x<img.width and y<img.height:
                if img.getpixel((x,y))!=255:
                    return False
    return True
        
def draw_sep(img, location):
    '''Draw a line at the middle of the gap discovered at the location
    :param img: A PIL.Image file
    :param location: A tuple (x,y) in pixel location
    '''
    from PIL import ImageDraw
    drawing_object=ImageDraw.Draw(img)
    x1=location[0]+int(gap_box[2]/2)
    x2=x1
    y1=location[1]
    y2=y1+gap_box[3]
    drawing_object.rectangle((x1,y1,x2,y2), fill='black', outline='black')
    
def process_img(img):
    '''Takes in an image of text and adds black vertical bars to break up columns
    :param img: A PIL.Image file
    :return: A modified PIL.Image file
    '''
    for x in range(img.width):
        for y in range(img.height):
            if (gap_check(img, (x,y))):
                draw_sep(img, (x,y))
    return img
i=Image.open('readonly/two_col.png').convert('L')
i=process_img(i)
display(i)


display(show_boxes(i))

#Comparing data structures
import cv2 as cv
img=cv.imread('readonly/floyd.jpg')
gray=cv.cvtColor(img, cv.COLOR_BGR2GRAY)
import inspect
inspect.getmro(type(gray))

gray

from PIL import Image
image=Image.fromarray(gray,'L')
display(image)

import numpy as np
single_dim=np.array([25,50,25,10,10])
double_dim=np.array([single_dim])
double_dim

display(Image.fromarray(double_dim, 'L'))

double_dim.shape

img.shape
first_pixel=img[0][0]
first_pixel

print('Original Image')
print(gray)
print('New Image')
image1d=np.reshape(gray,(1,gray.shape[0]*gray.shape[1]))
print(image1d)

import cv2 as cv
img=cv.imread('readonly/two_col.png')
gray=cv.cvtColor(img, cv.COLOR_BGR2GRAY)

gray[2:4,1:3]
np.count_nonzero(gray[2:4,1:3])

white_matrix=np.full((12,12),255,dtype=np.uint8)
display(Image.fromarray(white_matrix,'L'))
white_matrix

white_matrix[:,6]=np.full((1,12),0,dtype=np.uint8)
display(Image.fromarray(white_matrix,'L'))
white_matrix

#OpenCV
import cv2 as cv
face_cascade=cv.CascadeClassifier('readonly/haarcascade_frontalface_default.xml')
eye_cascade=cv.CascadeClassifier('readonly/haarcascade_eye.xml')
img=cv.imread('readonly/floyd.jpg')
gray=cv.cvtColor(img, cv.COLOR_BGR2GRAY)
faces=face_cascade.detectMultiScale(gray)
faces
faces.tolist()[0]

from PIL import Image
pil_img=Image.fromarray(gray,mode='L')
from PIL import ImageDraw
drawing=ImageDraw.Draw(pil_img)
rec=faces.tolist()[0]
drawing.rectangle(rec, outline='white')
display(pil_img)

pil_img=Image.fromarray(gray, mode='L')
drawing=ImageDraw.Draw(pil_img)
drawing.rectangle((rec[0],rec[1],rec[0]+rec[2],rec[1]+rec[3]), outline='white')
display(pil_img)

img=cv.imread('readonly/msi_recruitment.gif')
display(Image.fromarray(img))
pil_img=Image.open('readonly/msi_recruitment.gif')
opencv_version=pil_img.convert('L')
opencv_version.save('msi_recruitment.png')

cv_img=cv.imread('msi_recruitment.png')
faces=face_cascade.detectMultiScale(cv_img)
pil_img=Image.open('readonly/msi_recruitment.gif')
drawing=ImageDraw.Draw(pil_img)
for x,y,w,h in faces:
    drawing.rectangle((x,y,x+w,y+h),outline='white')
display(pil_img)

pil_img.mode

pil_img=Image.open('readonly/msi_recruitment.gif')
pil_img=pil_img.convert('RGB')
pil_img.mode

drawing=ImageDraw.Draw(pil_img)
for x,y,w,h in faces:
    drawing.rectangle((x,y,x+w,y+h),outline='white')
display(pil_img)

cv_img_bin=cv.threshold(img,120,255,cv.THRESH_BINARY)[1] # returns a list, we want the second value
# Now do the actual face detection
faces = face_cascade.detectMultiScale(cv_img_bin)
# Now lets see the results
show_rects(faces)

faces = face_cascade.detectMultiScale(cv_img,1.05)
# Show those results
show_rects(faces)
# Now lets also try 1.15
faces = face_cascade.detectMultiScale(cv_img,1.15)
# Show those results
show_rects(faces)
# Finally lets also try 1.25
faces = face_cascade.detectMultiScale(cv_img,1.25)
# Show those results
show_rects(faces)

%timeit face_cascade.detectMultiScale(cv_img,1.05)
%timeit face_cascade.detectMultiScale(cv_img,1.15)

#More jupyter widgets
from ipywebrtc import CameraStream, ImageRecorder
help(CameraStream)

camera = CameraStream.facing_user(audio=False)
# The next object we want to look at is the ImageRecorder
help(ImageRecorder)

image_recorder = ImageRecorder(stream=camera)
image_recorder.recording=True
# Now lets download the image
image_recorder.download()
# Then lets inspect the type of the image
type(image_recorder.image)

import PIL.Image
# And lets import io
import io
# And now lets create a PIL image from the bytes
img = PIL.Image.open(io.BytesIO(image_recorder.image.value))
# And render it to the screen
display(img)
